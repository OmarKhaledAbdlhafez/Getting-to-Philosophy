{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Getting to Philosophy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1SEAs10iQc9nIyie+3EV8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmarKhaledAbdlhafez/Getting-to-Philosophy/blob/master/Getting_to_Philosophy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us2jdxYqUg0h",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction**\n",
        "Clicking on the first link in the main body of a Wikipedia article and repeating the process for subsequent articles would usually lead to the article Philosophy.\n",
        " \n",
        "The program should receive a Wikipedia link as an input, go to another normal link and repeat this process until either Philosophy page is reached, or we are in an article without any outgoing Wikilinks, or stuck in a loop.\n",
        " \n",
        "A \"normal link\" is a link from the main page article, not in a box, is blue (red is for non-existing articles), not in parentheses, not italic and not a footnote. You don't have to check style tables or other fancy things, it is enough that the script works with the current Wikipedia style (for example you can use 'class' attribute in Wikipedia tags). For easy validation, please print all visited links to the standard output.\n",
        " \n",
        "Use a 0.5 second timeout between queries to avoid heavy load on Wikipedia (sleep function from time module).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp4vPVrkLeQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib\n",
        "import time\n",
        "import sys\n",
        "import requests"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BfcXnM0LqW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_url = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
        "target_url = \"https://en.wikipedia.org/wiki/Philosophy\" \n",
        "visited_urls = [start_url]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vulvLzl2Lyxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_first_link(url):\n",
        "    \"\"\" \n",
        "     Get first link from the url\n",
        "\n",
        "     Parameters:\n",
        "     url : the link which contain link to reach \n",
        "\n",
        "     Returns:\n",
        "     The First link of the url    \n",
        "    \"\"\"\n",
        "    response = requests.get(url)\n",
        "    html = response.text\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    content_div = soup.find(id=\"mw-content-text\").find(class_=\"mw-parser-output\")\n",
        "    article_link = None\n",
        "    for element in content_div.find_all(\"p\", recursive=False):\n",
        "        if element.find(\"a\", recursive=False):\n",
        "            article_link = element.find(\"a\", recursive=False).get('href')\n",
        "            break\n",
        "\n",
        "    if not article_link:\n",
        "        return\n",
        "\n",
        "    \n",
        "    first_link = urllib.parse.urljoin(\n",
        "        'https://en.wikipedia.org/', article_link)\n",
        "\n",
        "    return first_link"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8-NEaMsL9zR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def continue_scraping(scraping_history, target_url, max_steps=50):\n",
        "\n",
        "  \"\"\" \n",
        "     check the history search \n",
        "\n",
        "     Parameters:\n",
        "     scraping_history : list contain all links that visted \n",
        "     target_url: the url which i wanna reach \n",
        "     max_steps : the maximum number of search should do \n",
        "     \n",
        "     Returns:\n",
        "      bool varaible t/f \n",
        "  \"\"\"\n",
        "  if scraping_history[-1] == target_url:\n",
        "        print(\"Target article reached\")\n",
        "        return False\n",
        "  elif len(scraping_history) > max_steps:\n",
        "        print(\"Maximum (50) searches reached, stoped.\")\n",
        "        return False\n",
        "  elif scraping_history[-1] in scraping_history[:-1]:\n",
        "        print(\"Stuck in loop \")\n",
        "        return False\n",
        "  else:\n",
        "        return True"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZxoSeGHU3mP",
        "colab_type": "text"
      },
      "source": [
        "# **Getting to Philosophy**\n",
        "- reaches the Philosophy article so end porgram\n",
        "- reaches 50 article without reaching the Philosophy article so end  \n",
        "- get into a article with no links\n",
        "- stuck in a loop\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uenFhktSMY2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "1dc26266-aa8c-4895-d178-92faf6ba8953"
      },
      "source": [
        "while continue_scraping(visited_urls, target_url):\n",
        "    print(visited_urls[-1])\n",
        "    first_link = find_first_link(visited_urls[-1])\n",
        "    if not first_link:\n",
        "        print(\"Reach an article with no links, search aborted.\")\n",
        "        break\n",
        "\n",
        "    visited_urls.append(first_link)\n",
        "    time.sleep(0.5)\n",
        "\n",
        "visited_urls=[start_url]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://en.wikipedia.org/wiki/Special:Random\n",
            "https://en.wikipedia.org/wiki/Pelagiidae\n",
            "https://en.wikipedia.org/wiki/Jellyfish\n",
            "https://en.wikipedia.org/wiki/Subphylum\n",
            "https://en.wikipedia.org/wiki/Zoological_nomenclature\n",
            "https://en.wikipedia.org/wiki/Convention_(norm)\n",
            "https://en.wiktionary.org/wiki/standard\n",
            "Reach an article with no links, search aborted.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}